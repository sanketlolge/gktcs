{% extends "base.html" %}

{% block content %}

		<div id="div1">
			<div class="container">
				<div class="row">

					<div class="col-md-12">
						<div id="course_desc"><br/>
						<div id="hadoop">
							<div class="">
								<div class="row" style="background: rgba(40, 55, 73, 0.1);margin:10px; padding-top:4px;padding-bottom:4px; border-radius:5px;">
									<div class="col-md-3 col-sm-3">
										<img class="img-responsive" id="header-logo" src="http://gktcs.in/GLMS/public/static/images/hadoop1.jpg" />
									</div>
									<div class="col-md-9 col-sm-9">
										<h3 style="margin-top: 2px;">Big Data and Hadoop</h3>
										<div id="span1">Become a Hadoop Expert by mastering MapReduce, Yarn, Pig, Hive, HBase, Oozie, Flume and Sqoop while working on industry based Use-cases and Projects.</div>
									</div>
								</div>
							</div>
							<div class="">
							<div class="row" style="margin:-5px; padding-top:10px;">
								<div class="col-md-4">
										<div id="screen1">
											<iframe width="560" height="315" src="//www.youtube.com/embed/A02SRdyoshM" frameborder="0" allowfullscreen></iframe>
										</div>
								</div>
								<div class="col-md-8">
									<h4 id="upcom" style="margin-top:0px;"><b>Upcoming Batches : </b></h4>
									<table class="table" id="table1">
										<thead>
										  <tr id="head1">
											<th>BATCH</th>
											<th>DAYS</th>
											<th>TIME(IST)</th>
											<th>PRICE</th>
											<th>&nbsp </th>
										  </tr>
										</thead>
										<tbody>
										  <tr>
											<td>Weekdays (Morning)</td>
											<td>Mon-Fri (15 Days)</td>
											<td>06:00 AM- 08:00 AM</td>
											<td>20,000</td>
											<td id="enr">Enroll>></td>
										  </tr>
										  <tr>
											<td>Weekdays (Evening)</td>
											<td>Mon-Fri (15 Days)</td>
											<td>08:00 PM- 10:00 PM</td>
											<td>20,000</td>
											<td id="enr">Enroll>></td>
										  </tr>
										  <tr>
											<td>Weekend (Morning)</td>
											<td>Sat,Sun (5-Weeks)</td>
											<td>07:30 AM- 10:30 AM</td>
											<td>20,000</td>
											<td id="enr">Enroll>></td>
										  </tr>
										  <tr>
											<td>Weekend (Evening)</td>
											<td>Sat,Sun (5-Weeks)</td>
											<td>07:30 PM- 10:30 PM</td>
											<td>20,000</td>
											<td id="enr">Enroll>></td>
										  </tr>
										</tbody>
									 </table>
								</div>
							</div>
							<div style="padding:10px;">
								<h3 class="" style="color:#00A4CB; text-align:center; margin-top:0px;"> About Course</h3>	
								<div id="descripti" class="">
									<ul id = "myTab" class = "nav nav-tabs">
									   <li class = "active">
										  <a href = "#habout" data-toggle = "tab">
											 About The Course
										  </a>
									   </li>
									   
									   <li><a href = "#hCurriculum" data-toggle = "tab">Curriculum</a></li>
									   
									   <li><a href = "#hFAQ" data-toggle = "tab">FAQ's</a></li>
									   
									   <li><a href = "#hCertification" data-toggle = "tab">Certification</a></li>
									   
									   <li><a href = "#hReviews" data-toggle = "tab">Reviews</a></li>
										
										
									</ul>

									<div id = "myTabContent" class = "tab-content">

									   <div class = "tab-pane fade in active" id = "habout">
										  <h4>About The Course</h4>
											<p><div style="text-align:justify;">The Big Data and Hadoop training course from GKTCS is designed to enhance your knowledge and skills to become a successful Hadoop developer. In-depth knowledge of core concepts will be covered in the course along with implementation on varied industry use-cases.</div></p>
												<h4>Course Objectives</h4>
											<p><div style="text-align:justify;"><div>By the end of the course, &nbsp;you will:&nbsp;</div><div>1. Master the concepts of HDFS and MapReduce framework&nbsp;</div><div>2. Understand Hadoop 2.x Architecture&nbsp;</div><div>3. Setup Hadoop Cluster and write Complex MapReduce programs&nbsp;</div><div>4. Learn data loading techniques using Sqoop and Flume&nbsp;</div><div>5. Perform data analytics using Pig, Hive and YARN&nbsp;</div><div>6. Implement HBase and MapReduce integration&nbsp;</div><div>7. Implement Advanced Usage and Indexing&nbsp;</div><div>8. Schedule jobs using Oozie&nbsp;</div><div>9. Implement best practices for Hadoop development&nbsp;</div><div>10. Work on a real life Project on Big Data Analytics</div></div></p>
												<h4>Who should go for this course?</h4>
											<p><div style="text-align:justify;"><div>Today, Hadoop has become &nbsp;a cornerstone of every business technology professional. To stay ahead in the game, Hadoop has become a must-know technology for the following professionals:</div><div>1. Analytics professionals&nbsp;</div><div>2. BI /ETL/DW professionals&nbsp;</div><div>3. Project managers</div><div>4. Testing professionals&nbsp;</div><div>5. Mainframe professionals&nbsp;</div><div>6. Software developers and architects&nbsp;</div><div>7. Graduates aiming to build a successful career around Big Data</div></div></p>
												<h4>Why learn Big Data and Hadoop?</h4>
											<p><div style="text-align:justify;"><div>CIOs are making Hadoop their platform of choice in 2015. For better career prospects, bigger job opportunities and financial growth, Hadoop is a must-know.&nbsp;</div><div>Check out these GKTCS blogs to know why Hadoop training is critical:</div><div>http://www.GKTCS.co/blog/how-essential-is-hadoop-training/</div><div>http://www.GKTCS.co/blog/big-data-leads-economic-growth/</div></div></p>
												<h4>What are the pre-requisites for this Course?</h4>
											<p><div style="text-align:justify;"><div>You can master Hadoop, irrespective of your IT background. While basic knowledge of Core Java and SQL might help, it is not a pre-requisite for learning Hadoop.&nbsp;</div><div>In case you wish to brush-up your Java skills, GKTCS offers you a complimentary self-paced course: "Java essentials for Hadoop".</div></div></p>
												<h4>How will I execute the Practicals?</h4>
											<p><div style="text-align:justify;">For the practicals, we will help you to setup GKTCS's Virtual Machine in your system with local access. The detailed installation guides are provided in the LMS for setting up your environment. In case your system doesn't meet the pre-requisites e.g. 4GB RAM, you will be provided remote access to the GKTCS cluster. In case you experience any issues, our 24*7 support team will be happy to assist you.</div></p>
												<h4>Which Case-Studies will be a part of the Course?</h4>
											<p><div style="text-align:justify;"><div>Towards the end of the course, you will be working on a live project where you will be using PIG, HIVE, HBase and MapReduce to perform Big Data analytics.&nbsp;</div><div>Here are the few industry-specific Big Data case studies e.g. Finance, Retail, Media, Aviation etc. which you can consider foryour project work:</div><div><br></div><div><b>Project #1: </b>Analyze social bookmarking sites to find insights</div><div><b>Industry: </b>Social Media</div><div><b>Data: </b>It comprises of the information gathered from sites like reddit.com, stumbleupon.com which are bookmarking sites and allow you to bookmark, review, rate, search various links on any topic.reddit.com, stumbleupon.com, etc. A bookmarking site allows you to bookmark, review, rate, search various links on any topic. The data is in XML format and contains various links/posts URL, categories defining it and the ratings linked with it.&nbsp;</div><div><b>Problem Statement: </b>Analyze the data in the Hadoop ecosystem to:</div><div>1. Fetch the data into a Hadoop Distributed File System and analyze it with the help of MapReduce, Pig and Hive to find the top rated links based on the user comments, likes etc.</div><div>2. Using MapReduce, convert the semi-structured format (XML data) into a structured format and categorize the user rating as positive and negative for each of the thousand links.</div><div>3. Push the output HDFS and then feed it into PIG, which splits the data into two parts: Category data and Ratings data.</div><div>4. Write a fancy Hive Query to analyze the data further and push the output is into relational database (RDBMS) using Sqoop.</div><div>5. Use a web server running on grails/java/ruby/python that renders the result in real time processing on a website.</div><div><br></div><div><b>Project #2: </b>Customer Complaints Analysis</div><div><b>Industry: </b>Retail</div><div><b>Data: </b>Publicly available dataset, containing a few lakh observations with attributes like; CustomerId, Payment Mode, Product Details, Complaint, Location, Status of the complaint, etc.&nbsp;</div><div><b>Problem Statement: </b>Analyze the data in the Hadoop ecosystem to:</div><div>1. Get the number of complaints filed under each product</div><div>2. Get the total number of complaints filed from a particular location</div><div>3. Get the list of complaints grouped by location which has no timely response</div><div><br></div><div><b>Project #3:</b> Tourism Data Analysis</div><div><b>Industry: </b>Tourism</div><div><b>Data: </b>The dataset comprises attributes like: City pair (combination of from and to), adults traveling, seniors traveling, children traveling, air booking price, car booking price, etc.</div><div><b>Problem Statement: </b>Find the following insights from the data:</div><div>1. Top 20 destinations people frequently travel to: Based on given data we can find the most popular destinations where people travel frequently, based on the specific initial number of trips booked for a particular destination</div><div>2. Top 20 locations from where most of the trips start based on booked trip count</div><div>3. Top 20 high air-revenue destinations, i.e the 20 cities that generate high airline revenues for travel, so that the discount offers can be given to attract more bookings for these destinations.</div><div><br></div><div><b>Project #4: </b>Airline Data Analysis</div><div><b>Industry: </b>Aviation</div><div><b>Data: </b>Publicly available dataset which contains the flight details of various airlines such as: Airport id, Name of the airport, Main city served by airport, Country or territory where airport is located, Code of Airport, Decimal degrees, Hours offset from UTC, &nbsp;Timezone, etc.</div><div><b>Problem Statement: </b>Analyze the airlinesâ€™ data to:</div><div>1. Find list of airports operating in the country</div><div>2. Find the list of airlines having zero stops</div><div>3. List of airlines operating with code share</div><div>4. Which country (or) territory has the highest number of airports</div><div>5. Find the list of active airlines in the United States</div><div><br></div><div><b>Project #5: </b>Analyze Loan Dataset</div><div><b>Industry: </b>Banking and Finance</div><div><b>Data: </b>Publicly available dataset which contains complete details of all the loans issued, including the current loan status (Current, Late, Fully Paid, etc.) and latest payment information.</div><div><b>Problem Statement: </b>Find the number of cases per location and categorize the count with respect to reason for taking loan and display the average risk score.</div><div><br></div><div><b>Project #6: </b>Analyze Movie Ratings</div><div><b>Industry: </b>Media</div><div><b>Data: </b>Publicly available data from sites like rotten tomatoes, IMDB, etc.</div><div><b>Problem Statement: </b>Analyze the movie ratings by different users to:</div><div>1. Get the user who has rated the most number of movies</div><div>2. Get the user who has rated the least number of movies</div><div>3. Get the count of total number of movies rated by user belonging to a specific occupation&nbsp;</div><div>4. Get the number of underage users</div><div><br></div><div><b>Project #7: </b>Analyze YouTube data</div><div><b>Industry: </b>Social Media</div><div><b>Data: </b>It is about the YouTube videos and contains attributes such as: VideoID, Uploader, Age, Category, Length, views, ratings, comments, etc.</div><div><b>Problem Statement: </b>Identify the top 5 categories in which the most number of videos are uploaded, the top 10 rated videos, and the top 10 most viewed videos.</div><div>Apart from these there are some twenty more use-cases to choose:</div><div>Market data Analysis</div><div>Twitter Data Analysis</div></div></p>


									   </div>
									   
									   <div class = "tab-pane fade" id = "hCurriculum">
											<h4>
											1. Understanding Big Data and Hadoop 
														</h4>  
														<p><div>   <b>Learning
												Objectives - </b>        <span>In this module,
												  you will understand Big Data, the limitations of the existing
												  solutions for Big Data problem, how Hadoop solves the Big Data
												  problem, the common Hadoop ecosystem components, Hadoop
												  Architecture, HDFS, Anatomy of File Write and Read, Rack Awareness.</span></div>
												<p>
												<br /><strong>Topics
											  - </strong>        <span>Big Data,
												  Limitations and Solutions of existing Data Analytics Architecture,
												  Hadoop, Hadoop Features, Hadoop Ecosystem, Hadoop 2.x core
												  components, Hadoop Storage: HDFS, Hadoop Processing: MapReduce
												  Framework, Anatomy of File Write and Read, Rack Awareness.</span></p> </p>
																	<h4>
															2. Hadoop Architecture and HDFS 
														</h4>  
														<p><div style="text-align:justify;"><b>Learning Objectives -</b> In this module, you will learn the Hadoop Cluster Architecture, Important Configuration files in a Hadoop Cluster, Data Loading Techniques. </div><div style="text-align:justify;"><br /></div><div style="text-align:justify;"><b>Topics -</b> Hadoop 2.x Cluster Architecture - Federation and High Availability, A Typical Production Hadoop Cluster, Hadoop Cluster Modes, Common Hadoop Shell Commands, Hadoop 2.x Configuration Files, Password-Less SSH, MapReduce Job Execution, Data Loading Techniques: Hadoop Copy Commands, FLUME, SQOOP.</div> </p>
																	<h4>
															3. Hadoop MapReduce Framework - I 
														</h4>  
														<p><div>   <b>Learning Objectives
											  - </b>In this module, you will understand   Hadoop MapReduce
											  framework and the working of MapReduce on data stored   in HDFS. You
											  will learn about YARN concepts in MapReduce.</div>
											   <div>   <br /></div>
											   <div>   <b>Topics - </b>MapReduce
											  Use   Cases, Traditional way Vs MapReduce   way, Why MapReduce, Hadoop
											  2.x MapReduce Architecture, Hadoop 2.x MapReduce Components, YARN   MR
											  Application Execution Flow, YARN   Workflow, Anatomy of MapReduce
											  Program, Demo on MapReduce.</div> </p>
																	<h4>
															4. Hadoop MapReduce Framework - II 
														</h4>  
														<p><div>        <b>Learning
												Objectives</b>     <span> - In this
												  module, you will understand concepts like Input Splits in
												  MapReduce, Combiner &amp; Partitioner and Demos on MapReduce using
												  different data sets.</span></div>
											  <div>        <span>       <br /></span></div>
											  <div>        <span>
												  <b>Topics</b> - Input Splits, Relation between Input Splits
												  and HDFS Blocks, MapReduce Job Submission Flow, Demo of Input
												  Splits, MapReduce: Combiner &amp; Partitioner, Demo on
												  de-identifying Health Care Data set, Demo on Weather Data set.</span></div> </p>
																	<h4>
															5. Advanced MapReduce 
														</h4>  
														<p><div>   <b>Learning Objectives
											  -&nbsp;</b>In this module, you will learn   Advanced MapReduce concepts
											  such as Counters, Distributed Cache,   MRunit, Reduce Join, Custom
											  Input Format, Sequence Input Format and   how to deal with complex
											  MapReduce programs.</div>
											  <div>   <br></div>
											  <div>   <b>Topics -&nbsp;</b>Counters,
											  Distributed Cache, MRunit, Reduce Join, Custom Input Format, Sequence
											  Input Format.</div> </p>
																	<h4>
															6. Pig 
														</h4>  
														<p><div>   <b>Learning Objectives
											  - </b>In this module, you will learn Pig,   types of use case we
											  can use Pig, tight coupling between Pig and   MapReduce, and Pig Latin scripting.</div>
											  <div>   <b>     <br /></b></div>
											  <div>   <b>Topics -</b> About Pig,
											  MapReduce Vs Pig, Pig Use Cases,   Programming Structure in Pig, Pig
											  Running Modes, Pig components, Pig   Execution, Pig Latin Program,
											  Data Models in Pig, Pig Data Types.</div>
											  <div>Pig Latin : Relational Operators,
											  File   Loaders, Group Operator, COGROUP Operator, Joins and COGROUP,
											  Union,   Diagnostic Operators, Pig UDF, Pig Demo on Healthcare Data   set.</div> </p>
																	<h4>
															7. Hive 
														</h4>  
														<p><div>   <b>Learning Objectives -</b> This
											  module will help you in   understanding Hive concepts, Loading and
											  Querying Data in Hive and   Hive UDF.<b> </b></div>
											 <div>   <b>     <br /></b></div>
											 <div>   <b>Topics - </b>Hive
											  Background, Hive Use Case, About Hive, Hive   Vs Pig, Hive
											  Architecture and Components, Metastore in Hive,   Limitations of Hive,
											  Comparison with Traditional Database, Hive Data   Types and Data
											  Models, Partitions and Buckets, Hive Tables(Managed   Tables and
											  External Tables), Importing Data, Querying Data, Managing   Outputs,
											  Hive Script, Hive UDF, Hive Demo on Healthcare Data set.</div> </p>
																	<h4>
															8. Advanced Hive and HBase 
														</h4>  
														<p><div>   <b>Learning Objectives
											  -&nbsp;</b>In this module, you will understand   Advanced Hive concepts
											  such as UDF, Dynamic Partitioning. You will also   acquire in-depth
											  knowledge of HBase, HBase Architecture and its components.</div>
											  <div>   <b>     <br></b></div>
											  <div>   <b>Topics -&nbsp;</b>Hive QL:
											  Joining Tables, Dynamic Partitioning,   Custom Map/Reduce Scripts,
											  Hive : Thrift Server, User Defined   Functions.</div>
											  <div>HBase: Introduction to NoSQL
											  Databases   and HBase, HBase v/s RDBMS, HBase Components, HBase
											  Architecture,   HBase Cluster Deployment.</div> </p>
																	<h4>
															9. Advanced HBase 
														</h4>  
														<p><div>   <b>Learning Objectives
											  -&nbsp;</b>This module will cover Advanced HBase   concepts. We will
											  see demos on Bulk Loading , Filters. You will also   learn what
											  Zookeeper is all about, how it helps in monitoring a   cluster, why
											  HBase uses Zookeeper.</div>
											  <div>   <b>     <br></b></div>
											  <div>   <b>Topics -&nbsp;</b>HBase Data
											  Model, HBase Shell, HBase Client API,   Data Loading Techniques,
											  ZooKeeper Data Model, Zookeeper Service,   Zookeeper, Demos on Bulk
											  Loading, Getting and Inserting Data, Filters   in HBase.</div> </p>
																	<h4>
															10. Oozie and Hadoop Project 
														</h4>  
														<p><div>   <b>Learning Objectives
											  - </b>In this module, you will understand   working of multiple
											  Hadoop ecosystem components together in a Hadoop   implementation to
											  solve Big Data problems. We will discuss multiple   data sets and
											  specifications of the project. This module will also   cover Flume
											  &amp; Sqoop demo and Apache Oozie Workflow Scheduler for   Hadoop Jobs.</div>
											  <div>   <b>     <br /></b></div>
											  <div>   <b>Topics - </b>Flume and
											  Sqoop Demo, Oozie, Oozie Components,   Oozie Workflow, Scheduling with
											  Oozie, Demo on Oozie Workflow, Oozie   Co-ordinator, Oozie Commands,
											  Oozie Web Console, Hadoop Project Demo.</div> </p>


									   </div>
									   
									   <div class = "tab-pane fade" id = "hFAQ">
										  <p></p>
									   </div>
									   
									   <div class = "tab-pane fade" id = "hCertification">
										  <h4>GKTCS Certification Process:</h4>
												<p>
													<div style="text-align: justify;">At the end of your course, you will
											  work on a real time Project. You will  receive a Problem Statement
											  along with a dataset to work. </div>
											<div style="text-align: justify;">
											  <br /></div>
											<div style="text-align: justify;">Once you are successfully through with
											  the project (reviewed by an expert),  you will be awarded a
											  certificate with a performance based grading. </div>
											<div style="text-align: justify;">
											  <br /></div>
											<div style="text-align: justify;">If your project is not approved in 1st
											  attempt, you can take additional  assistance to understand the
											  concepts better and reattempt the Project  free of cost.</div>    </p>

									   </div>
									   
									   <div class = "tab-pane fade" id = "hReviews">
										  <p></p>
									   </div>
									   
									</div>
										
									
								</div>
							</div>	
							</div><hr/>
						</div>
						</div>
					</div>
				</div>
			</div>	
		</div>	
{% endblock %}